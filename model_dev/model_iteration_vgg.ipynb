{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed8059e1-f900-4bf6-827a-3fad491ce8c9",
   "metadata": {},
   "source": [
    "## PyTorch Work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb41085-ee9e-4e4a-8519-58fb316d1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d14a25-1bbe-48d9-a075-7bb1afde3212",
   "metadata": {},
   "source": [
    "### Directory Structure Based Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d76bba84-e3c6-4fd8-8303-9c9ed3d9fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        #transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        #                     std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "mitosis_dataset = datasets.ImageFolder(root='../model_dev/data_sample/train', \n",
    "                                           transform=data_transform)\n",
    "dataset_loader = torch.utils.data.DataLoader(mitosis_dataset,\n",
    "                                             batch_size=4, shuffle=True,\n",
    "                                             num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f7bd8f-5883-4b55-a80f-d8aee99404a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /home/jmwolf/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69fda37cd18644bf878ad19cf6f0e935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_0-b66bff10.pth\" to /home/jmwolf/.cache/torch/hub/checkpoints/squeezenet1_0-b66bff10.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3297e540d9ca45448cee248a6ab8bfe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/4.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/jmwolf/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7c479b3e5b49e6807c4ecfafd9c447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "squeezenet = models.squeezenet1_0(pretrained=True)\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "#densenet = models.densenet161(pretrained=True)\n",
    "#inception = models.inception_v3(pretrained=True)\n",
    "#googlenet = models.googlenet(pretrained=True)\n",
    "#shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "#mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "#resnext50_32x4d = models.resnext50_32x4d(pretrained=True)\n",
    "#wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\n",
    "#mnasnet = models.mnasnet1_0(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba7c1817-d1b1-40d0-a995-b6b2ac8c9d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlexNet',\n",
       " 'ConvNeXt',\n",
       " 'DenseNet',\n",
       " 'EfficientNet',\n",
       " 'GoogLeNet',\n",
       " 'GoogLeNetOutputs',\n",
       " 'Inception3',\n",
       " 'InceptionOutputs',\n",
       " 'MNASNet',\n",
       " 'MobileNetV2',\n",
       " 'MobileNetV3',\n",
       " 'RegNet',\n",
       " 'ResNet',\n",
       " 'ShuffleNetV2',\n",
       " 'SqueezeNet',\n",
       " 'VGG',\n",
       " 'VisionTransformer',\n",
       " '_GoogLeNetOutputs',\n",
       " '_InceptionOutputs',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_utils',\n",
       " 'alexnet',\n",
       " 'convnext',\n",
       " 'convnext_base',\n",
       " 'convnext_large',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'densenet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'detection',\n",
       " 'efficientnet',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'feature_extraction',\n",
       " 'googlenet',\n",
       " 'inception',\n",
       " 'inception_v3',\n",
       " 'mnasnet',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet',\n",
       " 'mobilenet_v2',\n",
       " 'mobilenet_v3_large',\n",
       " 'mobilenet_v3_small',\n",
       " 'mobilenetv2',\n",
       " 'mobilenetv3',\n",
       " 'optical_flow',\n",
       " 'quantization',\n",
       " 'regnet',\n",
       " 'regnet_x_16gf',\n",
       " 'regnet_x_1_6gf',\n",
       " 'regnet_x_32gf',\n",
       " 'regnet_x_3_2gf',\n",
       " 'regnet_x_400mf',\n",
       " 'regnet_x_800mf',\n",
       " 'regnet_x_8gf',\n",
       " 'regnet_y_128gf',\n",
       " 'regnet_y_16gf',\n",
       " 'regnet_y_1_6gf',\n",
       " 'regnet_y_32gf',\n",
       " 'regnet_y_3_2gf',\n",
       " 'regnet_y_400mf',\n",
       " 'regnet_y_800mf',\n",
       " 'regnet_y_8gf',\n",
       " 'resnet',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext50_32x4d',\n",
       " 'segmentation',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'shufflenetv2',\n",
       " 'squeezenet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'vgg',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'video',\n",
       " 'vision_transformer',\n",
       " 'vit_b_16',\n",
       " 'vit_b_32',\n",
       " 'vit_l_16',\n",
       " 'vit_l_32',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be67e078-1e8c-4139-b747-fd6ae77a033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18.fc = nn.Linear(512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a83f09-7f0b-45ba-aeb8-e08a03dfa0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "798012ae-cf72-4510-a524-20c2b3df17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = 'MITOS_Datasets/Data_CMC_COADEL_224_1/'\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 50\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62a50f27-713b-4cfe-b16b-7129e53d4570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3080'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e1219-52e8-4015-ad6e-95030f994cbe",
   "metadata": {},
   "source": [
    "### Define Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be49f874-24e4-4229-951b-fdd57adb1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5d3cd96-257f-484b-8d5f-095030789cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "        \n",
    "        #optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "        #scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "        #for epoch in range(10):\n",
    "        #     train(...)\n",
    "        #     val_loss = validate(...)\n",
    "        #     # Note that step should be called after validate()\n",
    "        #     scheduler.step(val_loss)\n",
    "        \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a24f32-ad1f-47c4-b580-6805b24be0d6",
   "metadata": {},
   "source": [
    "### Intialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec3f392d-7448-4cab-abf3-58e7cd37817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 128#224\n",
    "        \n",
    "    elif model_name == \"resnet152\":\n",
    "        \"\"\" Resnet152\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 128#224    \n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 128#224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 128#224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 128#224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5865afc7-9552-42f6-9a46-c1500305a742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model for this run\n",
    "# inception\n",
    "# densenet\n",
    "# squeezenet\n",
    "# vgg\n",
    "# alexnet\n",
    "# resnet\n",
    "model_name = \"vgg\"\n",
    "model_ft, input_size = initialize_model(model_name, 2, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16a72ee8-640b-4c48-a50c-aaad60ec113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.fc = nn.Linear(512, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f603de9-6efd-423c-bdfe-a550fdd8439f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e72c02e7-0c81-490c-8b2a-2f4802c53d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'Mitosis']}\n",
    "\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(mitosis_dataset, batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88b89e94-0077-49f5-9c99-a67690331be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ba6f036-0bea-44a8-8311-14cfa39b3874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "363d1c00-3b58-40bd-aa60-a9bd4be6f1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.6713 Acc: 0.6795\n",
      "val Loss: 0.5940 Acc: 0.6817\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.6935 Acc: 0.6748\n",
      "val Loss: 0.5880 Acc: 0.6931\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.7013 Acc: 0.6711\n",
      "val Loss: 0.5853 Acc: 0.7216\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.6956 Acc: 0.6754\n",
      "val Loss: 0.6418 Acc: 0.7212\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.6943 Acc: 0.6745\n",
      "val Loss: 0.6600 Acc: 0.7229\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.6960 Acc: 0.6752\n",
      "val Loss: 0.5751 Acc: 0.7013\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.6935 Acc: 0.6719\n",
      "val Loss: 0.5649 Acc: 0.7110\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.6998 Acc: 0.6717\n",
      "val Loss: 0.6546 Acc: 0.7208\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.6988 Acc: 0.6739\n",
      "val Loss: 0.5756 Acc: 0.7031\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.6934 Acc: 0.6766\n",
      "val Loss: 0.5613 Acc: 0.7227\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.6944 Acc: 0.6755\n",
      "val Loss: 0.5666 Acc: 0.7084\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.7040 Acc: 0.6721\n",
      "val Loss: 0.5806 Acc: 0.6886\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.7003 Acc: 0.6722\n",
      "val Loss: 0.5872 Acc: 0.7157\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.6992 Acc: 0.6736\n",
      "val Loss: 0.5679 Acc: 0.7169\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.6962 Acc: 0.6736\n",
      "val Loss: 0.7105 Acc: 0.7203\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.6989 Acc: 0.6711\n",
      "val Loss: 0.5728 Acc: 0.7102\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.6969 Acc: 0.6744\n",
      "val Loss: 0.5750 Acc: 0.7216\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.6957 Acc: 0.6736\n",
      "val Loss: 0.5869 Acc: 0.6901\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.6998 Acc: 0.6730\n",
      "val Loss: 0.5702 Acc: 0.7203\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.7049 Acc: 0.6751\n",
      "val Loss: 0.5978 Acc: 0.7231\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.7016 Acc: 0.6724\n",
      "val Loss: 0.6485 Acc: 0.6540\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.6913 Acc: 0.6745\n",
      "val Loss: 0.5697 Acc: 0.7225\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.6988 Acc: 0.6738\n",
      "val Loss: 0.5886 Acc: 0.7258\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.7009 Acc: 0.6743\n",
      "val Loss: 0.6050 Acc: 0.7217\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.6994 Acc: 0.6714\n",
      "val Loss: 0.5627 Acc: 0.7148\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.6995 Acc: 0.6733\n",
      "val Loss: 0.5797 Acc: 0.7086\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.7071 Acc: 0.6693\n",
      "val Loss: 0.6491 Acc: 0.6483\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.6963 Acc: 0.6739\n",
      "val Loss: 0.6609 Acc: 0.6284\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.6976 Acc: 0.6713\n",
      "val Loss: 0.5948 Acc: 0.6790\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.6978 Acc: 0.6736\n",
      "val Loss: 0.5589 Acc: 0.7177\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.6919 Acc: 0.6740\n",
      "val Loss: 0.6291 Acc: 0.7225\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.6924 Acc: 0.6749\n",
      "val Loss: 0.6967 Acc: 0.6114\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.7019 Acc: 0.6696\n",
      "val Loss: 0.5663 Acc: 0.7066\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.7033 Acc: 0.6738\n",
      "val Loss: 0.6012 Acc: 0.6803\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.7009 Acc: 0.6702\n",
      "val Loss: 0.5795 Acc: 0.7013\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.7018 Acc: 0.6730\n",
      "val Loss: 0.5888 Acc: 0.6864\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.6981 Acc: 0.6776\n",
      "val Loss: 0.6456 Acc: 0.6322\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.6991 Acc: 0.6738\n",
      "val Loss: 0.7040 Acc: 0.5876\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.6947 Acc: 0.6707\n",
      "val Loss: 0.6583 Acc: 0.7234\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.6982 Acc: 0.6734\n",
      "val Loss: 0.6590 Acc: 0.7243\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.7013 Acc: 0.6740\n",
      "val Loss: 0.5903 Acc: 0.6875\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.6778\n",
      "val Loss: 0.6946 Acc: 0.5848\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.7031 Acc: 0.6704\n",
      "val Loss: 0.6264 Acc: 0.7225\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.7026 Acc: 0.6713\n",
      "val Loss: 0.5965 Acc: 0.6788\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.6975 Acc: 0.6778\n",
      "val Loss: 0.5739 Acc: 0.7219\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.7012 Acc: 0.6734\n",
      "val Loss: 0.5607 Acc: 0.7154\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.7022 Acc: 0.6706\n",
      "val Loss: 0.5688 Acc: 0.7143\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.7079 Acc: 0.6680\n",
      "val Loss: 0.5848 Acc: 0.7257\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.6965 Acc: 0.6742\n",
      "val Loss: 0.5679 Acc: 0.7202\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.7040 Acc: 0.6707\n",
      "val Loss: 0.5917 Acc: 0.7247\n",
      "\n",
      "Training complete in 109m 9s\n",
      "Best val Acc: 0.725823\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30b5c8fc-6a03-431a-83b2-e1630ced9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, 'vgg_224_mitosis.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e282673-8ff0-4672-9ae3-a427ffcadf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ft = optim.SGD(params_to_update, lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e3050cb-5506-4c73-905b-ca95739c7b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.6214 Acc: 0.6950\n",
      "val Loss: 0.5387 Acc: 0.7279\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.6014 Acc: 0.7016\n",
      "val Loss: 0.5448 Acc: 0.7286\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.5846 Acc: 0.7066\n",
      "val Loss: 0.5330 Acc: 0.7300\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.5767 Acc: 0.7119\n",
      "val Loss: 0.5477 Acc: 0.7212\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.5727 Acc: 0.7141\n",
      "val Loss: 0.5405 Acc: 0.7283\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.5663 Acc: 0.7169\n",
      "val Loss: 0.5345 Acc: 0.7303\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.5641 Acc: 0.7175\n",
      "val Loss: 0.5351 Acc: 0.7333\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.5625 Acc: 0.7176\n",
      "val Loss: 0.5330 Acc: 0.7333\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.5624 Acc: 0.7185\n",
      "val Loss: 0.5336 Acc: 0.7332\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.5590 Acc: 0.7174\n",
      "val Loss: 0.5342 Acc: 0.7310\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.5635 Acc: 0.7154\n",
      "val Loss: 0.5332 Acc: 0.7296\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.5600 Acc: 0.7199\n",
      "val Loss: 0.5326 Acc: 0.7312\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.5611 Acc: 0.7181\n",
      "val Loss: 0.5350 Acc: 0.7331\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.5602 Acc: 0.7193\n",
      "val Loss: 0.5328 Acc: 0.7329\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.5614 Acc: 0.7176\n",
      "val Loss: 0.5343 Acc: 0.7318\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train and evaluate\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model_ft, hist \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_inception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minception\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[1;32m     21\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m dataloaders[phase]:\n\u001b[1;32m     25\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     26\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/wsi_eda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/wsi_eda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wsi_eda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/wsi_eda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wsi_eda/lib/python3.10/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/wsi_eda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py:297\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[0;32m--> 297\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m         storage \u001b[38;5;241m=\u001b[39m storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m~/anaconda3/envs/wsi_eda/lib/python3.10/multiprocessing/resource_sharer.py:57\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_resource_sharer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction\u001b[38;5;241m.\u001b[39mrecv_handle(conn)\n",
      "File \u001b[0;32m~/anaconda3/envs/wsi_eda/lib/python3.10/multiprocessing/resource_sharer.py:87\u001b[0m, in \u001b[0;36m_ResourceSharer.get_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m address, key \u001b[38;5;241m=\u001b[39m ident\n\u001b[1;32m     86\u001b[0m c \u001b[38;5;241m=\u001b[39m Client(address, authkey\u001b[38;5;241m=\u001b[39mprocess\u001b[38;5;241m.\u001b[39mcurrent_process()\u001b[38;5;241m.\u001b[39mauthkey)\n\u001b[0;32m---> 87\u001b[0m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetpid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m~/anaconda3/envs/wsi_eda/lib/python3.10/multiprocessing/connection.py:211\u001b[0m, in \u001b[0;36m_ConnectionBase.send\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_writable()\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7439d34-36cb-4b37-a99d-10bdcc3f67b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('data_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "173e1f66-1a3d-42b2-903c-b9c3cba81ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jmwolf/repos/XAI_Healthcare/model_dev/data_sample\n",
      "/home/jmwolf/repos/XAI_Healthcare/model_dev/data_sample\n"
     ]
    }
   ],
   "source": [
    "%cd '../model_dev/data_sample'\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5a068e1-7918-4a0b-a87a-4c1e7d3dfd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../data_sample/train'\n",
      "/home/jmwolf/repos/XAI_Healthcare/model_dev/data_sample/train\n",
      "/home/jmwolf/repos/XAI_Healthcare/model_dev/data_sample/train\n"
     ]
    }
   ],
   "source": [
    "os.mkdir('train')\n",
    "%cd '../data_sample/train'\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bfe8c1c-7982-4c99-93d8-aacda633bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('Mitosis')\n",
    "os.mkdir('Nonmitosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dee0cac2-db48-4e72-9085-0dfe18cb6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab72d232-46d7-4863-a78d-cc4b958d5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_m = '../model_dev/Data_CMC_COADEL_224_1/train/Mitosis'\n",
    "path_nm = '../model_dev/Data_CMC_COADEL_224_1/train/Nonmitosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5330fd2-a122-48aa-ae49-5de05c23176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_path_m = '../model_dev/data_sample/train/Mitosis'\n",
    "dest_path_nm = '../model_dev/data_sample/train/Nonmitosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65493f15-2616-486f-adc9-3cd4c7745bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jmwolf/repos/XAI_Healthcare/model_dev/data_sample/train\n",
      "/home/jmwolf/repos/XAI_Healthcare/model_dev\n",
      "/home/jmwolf/repos/XAI_Healthcare/model_dev\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "%cd ../../\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ef99f46-36dc-4e8f-ab7b-a59888e501ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mitosis_array = os.listdir(path_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9380c94f-1668-411d-809d-703b77fbc927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8739.jpg'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mitosis_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "657cef6a-6031-4719-8058-c1c3fb637048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10695"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(mitosis_array)\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "51f31305-5f17-4d2a-8441-e2df0337ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9fbc288c-6eb2-4461-b786-2d0af36709f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -r ../model_dev/Data_CMC_COADEL_224_1/train/Mitosis/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8af93926-25a5-4723-8668-1bf9a64e2133",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = random.sample(os.listdir(path_m), round((length*0.1)))\n",
    "for fname in filenames:\n",
    "    srcpath = os.path.join(path_m, fname)\n",
    "    destpath = os.path.join(dest_path_m, fname)\n",
    "    shutil.copyfile(srcpath, destpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d75e6c49-5d9a-4766-ad8c-300103632f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27256"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mitosis_array = os.listdir(path_nm)\n",
    "length = len(mitosis_array)\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f2d5785-df72-4810-9dcc-b666d9b80cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = random.sample(os.listdir(path_nm), round((length*0.1)))\n",
    "for fname in filenames:\n",
    "    srcpath = os.path.join(path_nm, fname)\n",
    "    destpath = os.path.join(dest_path_nm, fname)\n",
    "    shutil.copyfile(srcpath, destpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "755ed47c-d912-49e0-b9ef-5784ca7615ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2726"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mitosis_array = os.listdir(dest_path_nm)\n",
    "length = len(mitosis_array)\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "299e64ef-31c7-4efe-bd58-0bb6aa42bd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1752"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mitosis_array = os.listdir(dest_path_m)\n",
    "length = len(mitosis_array)\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2e006c13-6b8f-4b3b-8190-ca741f39388f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('../model_dev/data_sample/train/Nonmitosis/' + '.ipynb_checkpoints')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "778aa3cf-d7ee-4148-a22c-feb8fde8396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -r '../model_dev/data_sample/train/.ipynb_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3c030eb-cc5b-45a0-bbb9-843ffb03c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'Mitosis']}\n",
    "\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(mitosis_dataset, batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7b1dce23-4fc5-48ce-a338-e23cf1a481bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.6213 Acc: 0.6590\n",
      "val Loss: 0.5878 Acc: 0.6847\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.6170 Acc: 0.6579\n",
      "val Loss: 0.5844 Acc: 0.6894\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.6211 Acc: 0.6541\n",
      "val Loss: 0.5873 Acc: 0.6883\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.6212 Acc: 0.6525\n",
      "val Loss: 0.5819 Acc: 0.6907\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.6166 Acc: 0.6588\n",
      "val Loss: 0.5838 Acc: 0.6965\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.6188 Acc: 0.6570\n",
      "val Loss: 0.5861 Acc: 0.6912\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.6197 Acc: 0.6501\n",
      "val Loss: 0.5810 Acc: 0.6878\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.6130 Acc: 0.6563\n",
      "val Loss: 0.5812 Acc: 0.6903\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.6162 Acc: 0.6599\n",
      "val Loss: 0.5782 Acc: 0.6891\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.6116 Acc: 0.6637\n",
      "val Loss: 0.5774 Acc: 0.6889\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.6133 Acc: 0.6563\n",
      "val Loss: 0.5772 Acc: 0.6954\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.6131 Acc: 0.6628\n",
      "val Loss: 0.5772 Acc: 0.6903\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.6160 Acc: 0.6554\n",
      "val Loss: 0.5790 Acc: 0.6880\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.6131 Acc: 0.6568\n",
      "val Loss: 0.5730 Acc: 0.6990\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.6074 Acc: 0.6610\n",
      "val Loss: 0.5823 Acc: 0.6905\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.6176 Acc: 0.6599\n",
      "val Loss: 0.5727 Acc: 0.7028\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.6102 Acc: 0.6630\n",
      "val Loss: 0.5814 Acc: 0.6965\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.6127 Acc: 0.6583\n",
      "val Loss: 0.5863 Acc: 0.6909\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.6089 Acc: 0.6650\n",
      "val Loss: 0.5718 Acc: 0.7003\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.6087 Acc: 0.6594\n",
      "val Loss: 0.5709 Acc: 0.7023\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.6080 Acc: 0.6550\n",
      "val Loss: 0.5714 Acc: 0.7043\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.6077 Acc: 0.6697\n",
      "val Loss: 0.5703 Acc: 0.6987\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.6164 Acc: 0.6606\n",
      "val Loss: 0.5709 Acc: 0.7039\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.6028 Acc: 0.6708\n",
      "val Loss: 0.5749 Acc: 0.6894\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.6098 Acc: 0.6679\n",
      "val Loss: 0.5726 Acc: 0.7046\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.6214 Acc: 0.6519\n",
      "val Loss: 0.5679 Acc: 0.7104\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.6048 Acc: 0.6702\n",
      "val Loss: 0.5800 Acc: 0.7025\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.6124 Acc: 0.6650\n",
      "val Loss: 0.5681 Acc: 0.6979\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.6037 Acc: 0.6686\n",
      "val Loss: 0.5660 Acc: 0.7057\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.6104 Acc: 0.6650\n",
      "val Loss: 0.5632 Acc: 0.7088\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.6074 Acc: 0.6693\n",
      "val Loss: 0.5718 Acc: 0.6914\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.6124 Acc: 0.6561\n",
      "val Loss: 0.5658 Acc: 0.7099\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.6100 Acc: 0.6621\n",
      "val Loss: 0.5661 Acc: 0.6970\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.6120 Acc: 0.6666\n",
      "val Loss: 0.5798 Acc: 0.6813\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.6108 Acc: 0.6561\n",
      "val Loss: 0.5706 Acc: 0.7070\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.6119 Acc: 0.6619\n",
      "val Loss: 0.5635 Acc: 0.7108\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.6070 Acc: 0.6619\n",
      "val Loss: 0.5655 Acc: 0.7023\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.6003 Acc: 0.6740\n",
      "val Loss: 0.5655 Acc: 0.7124\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.6114 Acc: 0.6644\n",
      "val Loss: 0.5663 Acc: 0.7028\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.6067 Acc: 0.6568\n",
      "val Loss: 0.5655 Acc: 0.7072\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.6097 Acc: 0.6637\n",
      "val Loss: 0.5618 Acc: 0.7088\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.6040 Acc: 0.6706\n",
      "val Loss: 0.5614 Acc: 0.7113\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.6103 Acc: 0.6668\n",
      "val Loss: 0.5854 Acc: 0.6932\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.6090 Acc: 0.6626\n",
      "val Loss: 0.5714 Acc: 0.7061\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.6102 Acc: 0.6579\n",
      "val Loss: 0.5621 Acc: 0.7068\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.6035 Acc: 0.6711\n",
      "val Loss: 0.5690 Acc: 0.7025\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.6086 Acc: 0.6657\n",
      "val Loss: 0.5716 Acc: 0.6905\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.6184 Acc: 0.6530\n",
      "val Loss: 0.5627 Acc: 0.7092\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.6057 Acc: 0.6695\n",
      "val Loss: 0.5632 Acc: 0.7126\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.6086 Acc: 0.6610\n",
      "val Loss: 0.5624 Acc: 0.7124\n",
      "\n",
      "Training complete in 12m 31s\n",
      "Best val Acc: 0.712595\n"
     ]
    }
   ],
   "source": [
    "optimizer_ft = optim.SGD(params_to_update, lr=0.0001, momentum=0.9)\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342dbd2c-5810-4a6f-9787-769df236eca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
