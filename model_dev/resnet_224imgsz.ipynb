{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8367b35-7223-448c-92f3-f93ec06c3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7919faab-004d-4e2c-ae78-c68e9cafb77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        #transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        #                     std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "mitosis_dataset = datasets.ImageFolder(root='../MITOS_Datasets/Data_CMC_COADEL_224_1/train',\n",
    "                                           transform=data_transform)\n",
    "dataset_loader = torch.utils.data.DataLoader(mitosis_dataset,\n",
    "                                             batch_size=4, shuffle=True,\n",
    "                                             num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34d1f700-c83b-4b69-b7b5-0d76d3e688f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8cdefa-8e5d-41b3-a2c7-13ba7ecfab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = '../MITOS_Datasets/Data_CMC_COADEL_224_1/'\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "066300b1-9091-470f-bca4-80f78a261502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3080'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "154b04ab-b8a5-49ff-a314-c38b9fe873ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0abc59d-f00a-4b3b-bcaa-e75a44e1555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d7561c4-97de-4c1b-99fd-6b33ff8ba6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        #model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        #model_ft = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        model_ft = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"resnet152\":\n",
    "        \"\"\" Resnet152\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224    \n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 128#224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "868538c8-c544-4f02-98a3-46f33fe57a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /home/jmwolf/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897ea5736bbc4bfe8e4ddff5cab66c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"resnet\"\n",
    "model_ft, input_size = initialize_model(model_name, 2, feature_extract, use_pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1957be35-032f-4905-94bd-9a485574b55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adb94cee-570b-4fb1-93b1-20c72edf0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {x: torch.utils.data.DataLoader(mitosis_dataset, batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27370f8f-f50a-4bbb-ba71-43862b634dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7600b579-d88d-48ab-af47-83d897c60634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.6331 Acc: 0.6914\n",
      "val Loss: 0.5758 Acc: 0.7187\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.6922\n",
      "val Loss: 0.5828 Acc: 0.7293\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.6260 Acc: 0.6948\n",
      "val Loss: 0.5705 Acc: 0.7242\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.6309 Acc: 0.6931\n",
      "val Loss: 0.5943 Acc: 0.7278\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.6240 Acc: 0.6951\n",
      "val Loss: 0.5766 Acc: 0.7203\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.6327 Acc: 0.6925\n",
      "val Loss: 0.5875 Acc: 0.7261\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.6260 Acc: 0.6943\n",
      "val Loss: 0.5933 Acc: 0.6875\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.6321 Acc: 0.6919\n",
      "val Loss: 0.5783 Acc: 0.6953\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.6252 Acc: 0.6951\n",
      "val Loss: 0.6372 Acc: 0.7253\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.6273 Acc: 0.6959\n",
      "val Loss: 0.5671 Acc: 0.7269\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.6317 Acc: 0.6940\n",
      "val Loss: 0.5840 Acc: 0.7111\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.6955\n",
      "val Loss: 0.5794 Acc: 0.6942\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.6239 Acc: 0.6945\n",
      "val Loss: 0.5967 Acc: 0.6846\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.6255 Acc: 0.6930\n",
      "val Loss: 0.6840 Acc: 0.7232\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.6238 Acc: 0.6942\n",
      "val Loss: 0.8129 Acc: 0.5185\n",
      "\n",
      "Training complete in 22m 16s\n",
      "Best val Acc: 0.729328\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "339f417e-44d3-453c-b122-78590e6acfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.5892 Acc: 0.7056\n",
      "val Loss: 0.5621 Acc: 0.7125\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.5847 Acc: 0.7113\n",
      "val Loss: 0.5807 Acc: 0.7299\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.5853 Acc: 0.7080\n",
      "val Loss: 0.5903 Acc: 0.7280\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.5878 Acc: 0.7080\n",
      "val Loss: 0.5541 Acc: 0.7292\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.5882 Acc: 0.7096\n",
      "val Loss: 0.5808 Acc: 0.7264\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.5832 Acc: 0.7108\n",
      "val Loss: 0.5497 Acc: 0.7293\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.5858 Acc: 0.7115\n",
      "val Loss: 0.5503 Acc: 0.7242\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.5853 Acc: 0.7104\n",
      "val Loss: 0.6103 Acc: 0.6671\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.5872 Acc: 0.7092\n",
      "val Loss: 0.5836 Acc: 0.7281\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.5864 Acc: 0.7105\n",
      "val Loss: 0.5646 Acc: 0.7099\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.5844 Acc: 0.7096\n",
      "val Loss: 0.5721 Acc: 0.7287\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.5828 Acc: 0.7110\n",
      "val Loss: 0.5561 Acc: 0.7164\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.5851 Acc: 0.7090\n",
      "val Loss: 0.5487 Acc: 0.7260\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.5901 Acc: 0.7064\n",
      "val Loss: 0.5920 Acc: 0.7272\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.5867 Acc: 0.7096\n",
      "val Loss: 0.5481 Acc: 0.7282\n",
      "\n",
      "Training complete in 22m 6s\n",
      "Best val Acc: 0.729908\n"
     ]
    }
   ],
   "source": [
    "optimizer_ft = optim.Adam(params_to_update, lr=0.001)#, momentum=0.9)\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70fc4ed6-8e88-43ed-b5fc-95fd0de547a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, 'resnet50_mitosis.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566bbc23-5ae6-4c67-b1ac-1121007a76a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.5628 Acc: 0.7200\n",
      "val Loss: 0.5528 Acc: 0.7272\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.5531 Acc: 0.7243\n",
      "val Loss: 0.5463 Acc: 0.7312\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.5513 Acc: 0.7237\n",
      "val Loss: 0.5421 Acc: 0.7316\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.5471 Acc: 0.7256\n",
      "val Loss: 0.5526 Acc: 0.7328\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.5469 Acc: 0.7270\n",
      "val Loss: 0.5452 Acc: 0.7342\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.5468 Acc: 0.7279\n",
      "val Loss: 0.5628 Acc: 0.7296\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.5432 Acc: 0.7291\n",
      "val Loss: 0.5596 Acc: 0.7337\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.5465 Acc: 0.7292\n",
      "val Loss: 0.5693 Acc: 0.7291\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.5431 Acc: 0.7304\n",
      "val Loss: 0.5475 Acc: 0.7352\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.5449 Acc: 0.7282\n",
      "val Loss: 0.5465 Acc: 0.7351\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.5443 Acc: 0.7288\n",
      "val Loss: 0.5594 Acc: 0.7356\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.5441 Acc: 0.7280\n",
      "val Loss: 0.5728 Acc: 0.7289\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.5442 Acc: 0.7290\n",
      "val Loss: 0.5690 Acc: 0.7343\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.5428 Acc: 0.7289\n",
      "val Loss: 0.5646 Acc: 0.7357\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.5459 Acc: 0.7296\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab6f837-dbf9-4fa8-aa60-e6336666a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, 'resnet50_v2_mitosis.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
